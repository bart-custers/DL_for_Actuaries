{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the French MTPL Claims Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch.optim import NAdam\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "# Load the dataset (replace 'path_to_dataset.csv' with your actual file path)\n",
    "data = pd.read_csv('DL_for_Actuaries/data/freMTPL2freq.csv')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Step 2: Preprocess the Dataset\n",
    "# Preprocess the Dataset\n",
    "numerical_features = ['VehPower', 'VehAge', 'DrivAge','Density']\n",
    "categorical_features = ['Area', 'VehBrand', 'VehGas','Region']\n",
    "\n",
    "y = data['ClaimNb']\n",
    "X = data.drop(columns=['ClaimNb','Exposure','IDpol'], axis=1)\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "exposure = data['Exposure']\n",
    "\n",
    "# Split the dataset including the exposure\n",
    "X_train, X_test, y_train, y_test, exposure_train, exposure_test = train_test_split(\n",
    "    X, y, exposure, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Apply the preprocessing pipeline\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Fit a Generalized Linear Model (GLM) for frequency (Poisson)\n",
    "glm = PoissonRegressor()\n",
    "glm.fit(X_train, y_train, sample_weight=exposure_train)\n",
    "\n",
    "# Get GLM predictions\n",
    "glm_preds_train = glm.predict(X_train)\n",
    "glm_preds_test = glm.predict(X_test)\n",
    "\n",
    "# Evaluate GLM\n",
    "def evaluate_model(model_name, y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print(f\"{model_name} - RMSE: {rmse:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.3)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], color='red', linewidth=2)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(f'{model_name} Predictions vs. True Values')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(\"GLM\", y_test, glm_preds_test)\n",
    "\n",
    "# Add GLM predictions as features to the dataset\n",
    "X_train = np.hstack((X_train.toarray(), glm_preds_train.reshape(-1, 1)))\n",
    "X_test = np.hstack((X_test.toarray(), glm_preds_test.reshape(-1, 1)))\n",
    "\n",
    "# Step 4: Build the Combined Actuarial Neural Network (CANN)\n",
    "# Define the CANN model\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "cann_model = models.Sequential([\n",
    "    layers.Input(shape=(input_shape,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "cann_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the CANN model\n",
    "cann_model.fit(X_train, y_train, sample_weight=exposure_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate CANN\n",
    "cann_preds_test = cann_model.predict(X_test)\n",
    "evaluate_model(\"CANN\", y_test, cann_preds_test)\n",
    "\n",
    "# Step 5: Build the LocalGLMNet Model\n",
    "class LocalGLMNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes):\n",
    "        super(LocalGLMNet, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size, hidden_layer_sizes[0])]\n",
    "        )\n",
    "        self.hidden_layers.extend(\n",
    "            [\n",
    "                nn.Linear(hidden_layer_sizes[i], hidden_layer_sizes[i + 1])\n",
    "                for i in range(len(hidden_layer_sizes) - 1)\n",
    "            ]\n",
    "        )\n",
    "        self.last_hidden_layer = nn.Linear(hidden_layer_sizes[-1], input_size)\n",
    "        self.output_layer = nn.Linear(1, 1)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.inverse_link = torch.exp\n",
    "\n",
    "    def forward(self, features, exposure=None, attentions=False):\n",
    "        x = features\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.last_hidden_layer(x)\n",
    "        if attentions:\n",
    "            return x\n",
    "        skip_connection = torch.einsum(\"ij,ij->i\", x, features).unsqueeze(1)\n",
    "        x = self.output_layer(skip_connection)\n",
    "        x = self.inverse_link(x)\n",
    "        if exposure is None:\n",
    "            exposure = torch.ones_like(x, device=features.device)\n",
    "        x = x * exposure\n",
    "        return x\n",
    "\n",
    "# Step 6: Train the LocalGLMNet Model\n",
    "def train_model(X, v, y, device):\n",
    "    localglmnet = NeuralNetRegressor(\n",
    "        module=LocalGLMNet,\n",
    "        max_epochs=10,\n",
    "        criterion=nn.PoissonNLLLoss,\n",
    "        criterion__log_input=False,\n",
    "        module__input_size=X.shape[1],\n",
    "        module__hidden_layer_sizes=[64, 32, 16],\n",
    "        optimizer=NAdam,\n",
    "        lr=0.01,\n",
    "        batch_size=512,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    X_dict = {\"features\": X, \"exposure\": v}\n",
    "    localglmnet.fit(X_dict, y)\n",
    "    return localglmnet\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_torch = torch.FloatTensor(X_train)\n",
    "y_train_torch = torch.FloatTensor(y_train.values)\n",
    "X_test_torch = torch.FloatTensor(X_test)\n",
    "y_test_torch = torch.FloatTensor(y_test.values)\n",
    "\n",
    "# Example call to train the LocalGLMNet\n",
    "trained_model = train_model(X_train_torch, np.ones_like(y_train_torch), y_train_torch, device='cpu')\n",
    "\n",
    "# Evaluate LocalGLMNet\n",
    "localglmnet_preds_test = trained_model.predict(X_test_torch)\n",
    "evaluate_model(\"LocalGLMNet\", y_test, localglmnet_preds_test)\n",
    "\n",
    "# Step 7: Build the TabNet Model\n",
    "# Initialize and train the TabNet model\n",
    "tabnet = TabNetRegressor()\n",
    "\n",
    "y_train_normalized = (y_train / exposure_train).values.reshape(-1, 1)\n",
    "y_test_normalized = (y_test / exposure_test).values.reshape(-1, 1)\n",
    "\n",
    "# Train the TabNet model with normalized targets\n",
    "tabnet.fit(X_train, y_train_normalized,\n",
    "           eval_set=[(X_test, y_test_normalized)],\n",
    "           eval_metric=['rmse'],\n",
    "           max_epochs=10)\n",
    "\n",
    "# Evaluate TabNet\n",
    "tabnet_preds_test_normalized = tabnet.predict(X_test)\n",
    "tabnet_preds_test = tabnet_preds_test_normalized * exposure_test\n",
    "evaluate_model(\"TabNet\", y_test, tabnet_preds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
